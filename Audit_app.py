# packages importation
import streamlit as st, pandas as pd, numpy as np, io, uuid, shutil, os, platform, tempfile, logging, sys, requests, base64, json, csv
from pathlib import Path


# ---------------- CONFIG ---------------- #
TEMP_DIR    = Path(tempfile.gettempdir()) / "datacleaner"
TEMP_DIR.mkdir(exist_ok=True)
logging.basicConfig(level=logging.INFO, format="%(asctime)s | %(levelname)s | %(message)s",
                     handlers=[logging.FileHandler(TEMP_DIR / "app.log"), logging.StreamHandler(sys.stdout)])
log = logging.getLogger("datacleaner")
MAX_SIZE    = 500 * 1_000_000  # 500 Mo

# ---------------- LLM ‚Äì OPENROUTER ---------------- #
OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
LLM_MODEL      = "meta-llama/llama-3.2-3b-instruct"

# Remplacer votre fonction ask_llama existante par :

def ask_llama(prompt: str, max_tokens: int = 350, temperature: float = 0.2, 
              profile: dict = None) -> str | None:
    """Fonction LLM am√©lior√©e avec adaptation contextuelle"""
    
    headers = {
        "Authorization": f"Bearer {st.secrets['OPENROUTER_KEY']}",
        "HTTP-Referer": "https://datacleaner-pro.streamlit.app",
        "X-Title": "DataCleaner-Pro"
    }
    
    # System prompt adaptatif bas√© sur le profil
    if profile:
        if profile["type"] == "numerical":
            system_msg = """Tu es un Data Scientist expert en analyse num√©rique. 
            Tu r√©ponds de mani√®re technique mais accessible. Utilise des concepts statistiques.
            Sois pr√©cis avec les chiffres."""
        elif profile["type"] == "categorical":
            system_msg = """Tu es un expert en analyse cat√©gorielle.
            Concentre-toi sur les fr√©quences, proportions et relations entre cat√©gories.
            Propose des encodages adapt√©s."""
        elif profile["type"] == "temporal":
            system_msg = """Tu es un expert en s√©ries temporelles.
            Analyse les tendances, saisonnalit√©s et patterns temporels.
            Sugg√®re des m√©triques temporelles pertinentes."""
        else:
            system_msg = """Tu es un expert en data quality et nettoyage de donn√©es.
            Tu r√©ponds de mani√®re concise, technique et factuelle."""
    else:
        system_msg = """Tu es un assistant expert en data quality et nettoyage de donn√©es.
        R√©ponds de mani√®re concise et pr√©cise."""
    
    payload = {
        "model": LLM_MODEL,
        "messages": [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": prompt}
        ],
        "max_tokens": max_tokens,
        "temperature": temperature,
        "top_p": 0.1,
        "frequency_penalty": 0.1
    }
    
    try:
        r = requests.post(OPENROUTER_URL, headers=headers, json=payload, timeout=45)
        r.raise_for_status()
        response = r.json()
        
        if "choices" not in response or len(response["choices"]) == 0:
            log.error("R√©ponse LLM vide")
            return "Erreur: r√©ponse vide de l'IA."
            
        content = response["choices"][0]["message"]["content"].strip()
        
        if len(content.split()) < 3:
            log.warning("R√©ponse LLM trop courte")
            return "L'IA n'a pas pu g√©n√©rer une r√©ponse utile."
            
        return content
        
    except requests.exceptions.Timeout:
        log.error("Timeout LLM apr√®s 45s")
        return "D√©lai d√©pass√©. L'IA met trop de temps √† r√©pondre."
    except requests.exceptions.RequestException as e:
        log.error("Erreur r√©seau LLM: %s", e)
        return "Erreur de connexion √† l'IA. V√©rifiez votre cl√© API."
    except Exception as e:
        log.error("Erreur LLM inattendue: %s", e)
        return f"Erreur technique: {str(e)[:100]}"

# Analyse intelligente du dataset

def analyze_dataset_profile(df: pd.DataFrame) -> dict:
    """Analyse intelligente pour d√©terminer le type de dataset"""
    
    profile = {
        "type": "unknown",
        "characteristics": [],
        "suggested_questions": [],
        "domain_hints": [],
        "quality_score": 0
    }
    
    # 1. D√©tection du type de dataset
    num_cols = len(df.select_dtypes(include=np.number).columns)
    cat_cols = len(df.select_dtypes(include=['object', 'category']).columns)
    date_cols = len(df.select_dtypes(include=['datetime']).columns)
    total_cols = len(df.columns)
    
    if num_cols / total_cols > 0.7:
        profile["type"] = "numerical"
        profile["characteristics"].append("Donn√©es principalement num√©riques")
    elif cat_cols / total_cols > 0.7:
        profile["type"] = "categorical"
        profile["characteristics"].append("Donn√©es principalement cat√©gorielles")
    elif date_cols > 0:
        profile["type"] = "temporal"
        profile["characteristics"].append("Donn√©es temporelles pr√©sentes")
    
    # 2. D√©tection de domaine potentiel
    column_names = [col.lower() for col in df.columns]
    
    financial_indicators = ['price', 'cost', 'revenue', 'profit', 'salary', 'amount']
    customer_indicators = ['customer', 'client', 'user', 'email', 'phone', 'address']
    product_indicators = ['product', 'sku', 'item', 'category', 'brand']
    temporal_indicators = ['date', 'time', 'year', 'month', 'day', 'hour']
    health_indicators = ['patient', 'diagnosis', 'treatment', 'hospital', 'medical']
    
    indicators = [
        (financial_indicators, "financier"),
        (customer_indicators, "client/CRM"),
        (product_indicators, "produit/inventaire"),
        (temporal_indicators, "temporel/s√©rie chronologique"),
        (health_indicators, "m√©dical/sant√©")
    ]
    
    for indicator_list, domain in indicators:
        if any(indicator in ' '.join(column_names) for indicator in indicator_list):
            profile["domain_hints"].append(domain)
    
    # 3. Score de qualit√©
    quality_metrics = 0
    total_metrics = 4
    
    # M√©trique 1: Taux de valeurs manquantes
    na_percentage = df.isna().sum().sum() / (len(df) * len(df.columns))
    if na_percentage < 0.1:
        quality_metrics += 1
        profile["characteristics"].append(f"Peu de valeurs manquantes ({na_percentage:.1%})")
    else:
        profile["characteristics"].append(f"Valeurs manquantes √©lev√©es ({na_percentage:.1%})")
    
    # M√©trique 2: Coh√©rence des types
    type_consistency = df.apply(lambda x: x.map(type).nunique()).max()
    if type_consistency == 1:
        quality_metrics += 1
        profile["characteristics"].append("Types de donn√©es coh√©rents")
    
    # M√©trique 3: Balance num√©rique/cat√©goriel
    if 0.3 <= num_cols/total_cols <= 0.7:
        quality_metrics += 1
        profile["characteristics"].append("Mix √©quilibr√© num√©rique/cat√©goriel")
    
    # M√©trique 4: Taille raisonnable
    if len(df) > 1000:
        quality_metrics += 1
        profile["characteristics"].append("Dataset de taille substantielle")
    
    profile["quality_score"] = (quality_metrics / total_metrics) * 100
    
    # 4. Questions sugg√©r√©es bas√©es sur l'analyse
    if profile["type"] == "numerical":
        profile["suggested_questions"] = [
            "Quelles sont les corr√©lations entre les variables num√©riques?",
            "Y a-t-il des outliers significatifs?",
            "Quelles variables ont le plus d'impact sur la cible?",
            "Peux-tu proposer des transformations math√©matiques utiles?"
        ]
    elif profile["type"] == "categorical":
        profile["suggested_questions"] = [
            "Quelles sont les cat√©gories dominantes?",
            "Y a-t-il des d√©s√©quilibres dans les classes?",
            "Comment encoder ces variables pour du machine learning?",
            "Quelles associations entre cat√©gories?"
        ]
    elif profile["type"] == "temporal":
        profile["suggested_questions"] = [
            "Y a-t-il des tendances saisonni√®res?",
            "Quelle est la fr√©quence optimale d'analyse?",
            "Comment traiter les gaps temporels?",
            "Quelles m√©triques temporelles calculer?"
        ]
    
    # Questions g√©n√©riques bas√©es sur le domaine
    if "financier" in profile["domain_hints"]:
        profile["suggested_questions"].extend([
            "Calculer les ROI par segment?",
            "D√©tecter les anomalies de prix?",
            "Quelles tendances financi√®res?"
        ])
    
    # Ajouter des questions g√©n√©riques
    profile["suggested_questions"].extend([
        "Quelles sont les m√©triques cl√©s √† surveiller?",
        "Comment am√©liorer la qualit√© des donn√©es?",
        "Quels insights business puis-je en tirer?"
    ])
    
    return profile

def build_adaptive_prompt(df: pd.DataFrame, user_question: str, profile: dict) -> str:
    """Construit un prompt intelligent bas√© sur le type de dataset"""
    
    # Contexte optimis√© (concis)
    dataset_context = f"""
## CONTEXTE DATASET
- Type: {profile['type']} | Domaines: {', '.join(profile['domain_hints'][:2]) or 'G√©n√©ral'}
- Shape: {len(df)} lignes √ó {len(df.columns)} colonnes
- Types principaux: {', '.join([f'{k}({v})' for k,v in df.dtypes.value_counts().items()][:3])}
- NA: {df.isna().sum().sum()} ({df.isna().sum().sum()/(len(df)*len(df.columns))*100:.1f}%)
- Colonnes: {', '.join(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}
"""
    
    # Instructions adaptatives
    role_instructions = ""
    if profile["type"] == "numerical":
        role_instructions = "Tu es un Data Scientist expert en analyse num√©rique. Concentre-toi sur: statistiques, corr√©lations, distributions, transformations."
    elif profile["type"] == "categorical":
        role_instructions = "Tu es un expert en analyse cat√©gorielle. Concentre-toi sur: fr√©quences, encodages, associations, d√©s√©quilibres."
    elif profile["type"] == "temporal":
        role_instructions = "Tu es un expert en s√©ries temporelles. Concentre-toi sur: tendances, saisonnalit√©s, stationnarit√©, fen√™tres temporelles."
    else:
        role_instructions = "Tu es un expert en analyse de donn√©es. Fournis des insights pr√©cis et actionnables."
    
    # Prompt final
    prompt = f"""
{role_instructions}

{dataset_context}

## QUESTION UTILISATEUR
{user_question}

## FORMAT DE R√âPONSE
- **R√©sum√©** (1 phrase)
- **Analyse technique** (3 points max)
- **Recommandations** (actions concr√®tes)
- **Limitations** (ce que les donn√©es ne disent pas)

R√©ponds en fran√ßais, sois pr√©cis et adapt√© au type de donn√©es.
"""
    
    return prompt
# ---------------- CORE UTILS ---------------- #
def memory_opt(df: pd.DataFrame) -> tuple[pd.DataFrame, float]:
    before = df.memory_usage(deep=True).sum()
    df = df.copy()
    for c in df.columns:
        col = df[c]
        if col.dtype == "object" and col.nunique() / len(col) < 0.5:
            df[c] = col.astype("category")
        elif pd.api.types.is_integer_dtype(col):
            for dtype in (np.int8, np.int16, np.int32, np.int64):
                if col.min() >= np.iinfo(dtype).min and col.max() <= np.iinfo(dtype).max:
                    df[c] = col.astype(dtype); break
        elif pd.api.types.is_float_dtype(col):
            df[c] = pd.to_numeric(col, downcast="float")
    reduction = (before - df.memory_usage(deep=True).sum()) / before * 100
    return df, reduction

def clean_df(df: pd.DataFrame, params: dict) -> tuple[pd.DataFrame, list[str]]:
    logs, df = [], df.copy()
    
    # 1. Suppression des doublons
    if params["drop_dup"]:
        prev = len(df)
        df = df.drop_duplicates()
        if (d := prev - len(df)):
            logs.append(f"üóëÔ∏è {d} doublons supprim√©s")
            
    # 2. Normalisation des noms de colonnes
    if params["norm_cols"]:
        old = df.columns.tolist()
        df.columns = df.columns.str.strip().str.lower().str.replace(r"\W+", "_", regex=True)
        if old != df.columns.tolist():
            logs.append("üî† noms normalis√©s")
            
    # 3. Nettoyage du texte/cat√©gories (NOUVEAU)
    if params["text_clean"]:
        for c in df.columns:
            if df[c].dtype == "object" or pd.api.types.is_categorical_dtype(df[c]):
                # Conversion en cha√Æne, suppression des espaces, mise en minuscule (pour uniformit√©)
                df[c] = df[c].astype(str).str.strip().str.lower()
                # Re-categorisation si le type √©tait cat√©goriel
                if pd.api.types.is_categorical_dtype(df[c]):
                    df[c] = df[c].astype("category")
        logs.append(f"‚úçÔ∏è Nettoyage du texte (strip, minuscule) appliqu√©")

    # 4. Conversion automatique des types
    if params["auto_type"]:
        th = params["na_thresh"] / 100
        for c in df.columns:
            if df[c].dtype != "object": continue
            num = pd.to_numeric(df[c], errors="coerce")
            if num.notna().mean() >= th:
                df[c] = num; logs.append(f"{c} ‚Üí num"); continue
            try:
                dat = pd.to_datetime(df[c], errors="coerce", dayfirst=True)
                if dat.notna().mean() >= th:
                    df[c] = dat; logs.append(f"{c} ‚Üí date")
            except: pass
            
    # 5. Gestion des NA
    if params["handle_na"]:
        for c in df.columns:
            if df[c].isna().sum() == 0: continue
            if pd.api.types.is_numeric_dtype(df[c]):
                fill = df[c].median() if params["na_strat"] == "median" else df[c].mode()[0]
                df[c] = df[c].fillna(fill)
                logs.append(f"üìà {c} NA ‚Üí {params['na_strat']}")
            else:
                df[c] = df[c].fillna(params["na_fill"])
                logs.append(f"üìù {c} NA ‚Üí '{params['na_fill']}'")
                
    # 6. Plafonnement des Outliers (MISE √Ä JOUR)
    iqr_coeff = params["iqr_coeff"]
    if iqr_coeff > 0: # Le slider est > 0 si l'utilisateur veut appliquer le capping
        # FIX: Utilisation de select_dtypes pour garantir que nous traitons uniquement les types num√©riques purs.
        numeric_cols = df.select_dtypes(include=np.number).columns
        
        for c in numeric_cols:
            # S'assurer qu'il y a plus d'une valeur unique pour le calcul de quantile (pour √©viter IQR=0)
            if df[c].nunique() > 1:
                Q1 = df[c].quantile(0.25)
                Q3 = df[c].quantile(0.75)
                IQR = Q3 - Q1
                
                # Utiliser le coefficient choisi par l'utilisateur
                lower_bound = Q1 - iqr_coeff * IQR
                upper_bound = Q3 + iqr_coeff * IQR
                
                # Appliquer le capping
                df[c] = df[c].clip(lower_bound, upper_bound)
                logs.append(f"üìà {c} valeurs aberrantes plafonn√©es (coeff {iqr_coeff:.1f} IQR)")
                
    # 7. Suppression des colonnes √† faible variance
    if params["drop_low_var"]:
        cols_to_drop = []
        for c in df.columns:
            if df[c].nunique() <= 1:
                # Colonnes avec 0 ou 1 valeur unique
                cols_to_drop.append(c)
                logs.append(f"üóëÔ∏è {c} supprim√© (unique <= 1)")
            elif df[c].dtype == "object" or pd.api.types.is_categorical_dtype(df[c]):
                # Colonnes textuelles presque constantes (>99% m√™me valeur)
                if not df[c].empty:
                    most_freq_ratio = df[c].value_counts(normalize=True).iloc[0]
                    if most_freq_ratio > 0.99: 
                        cols_to_drop.append(c)
                        logs.append(f"üóëÔ∏è {c} supprim√© (texte >99% constant)")
            
        df = df.drop(columns=cols_to_drop, errors='ignore')

    # 8. Optimisation de la m√©moire (toujours en dernier)
    df, gain = memory_opt(df)
    if gain > 5:
        logs.append(f"üíæ m√©moire -{gain:.1f}%")
        
    return df, logs

def build_report(df: pd.DataFrame, title: str, minimal: bool) -> Path | None:
    """Tente de g√©n√©rer le rapport ydata-profiling ou retourne None si √©chec."""
    try:
        # Importation dynamique pour √©viter le plantage si la d√©pendance n'est pas l√†.
        from ydata_profiling import ProfileReport
        file = TEMP_DIR / f"report_{title.replace(' ','_')}_{uuid.uuid4().hex}.html"
        ProfileReport(df, title=title, minimal=minimal).to_file(str(file))
        return file
    except Exception as e:
        # Log l'erreur (probablement ModuleNotFoundError si ydata-profiling est manquante)
        log.warning("ydata fail: %s. Utilisation du rapport de secours.", e)
        return None

def fallback_report(df: pd.DataFrame, title: str):
    st.subheader(f"üìã Rapport basique ‚Äì {title}")
    
    # Ajout d'une alerte visible si le rapport complet manque
    st.warning("Rapport complet manquant. Assurez-vous que 'ydata-profiling' est install√© (via requirements.txt) et que la g√©n√©ration n'a pas √©chou√©.")
    
    c1, c2 = st.columns(2)
    with c1:
        st.write("**Types & uniques**")
        st.dataframe(df.dtypes.astype(str).to_frame("type").assign(uniques=df.nunique()))
    with c2:
        na = df.isna().sum().to_frame("NA").query("NA > 0")
        st.write("**Valeurs manquantes**")
        st.dataframe(na if not na.empty else "Aucune")
    st.write("**Aper√ßu**")
    st.dataframe(df.head(10))

def show_report(file: Path):
    b64 = base64.b64encode(file.read_bytes()).decode()
    html = f'<iframe src="data:text/html;base64,{b64}" width="100%" height="700" style="border:none;"></iframe>'
    st.components.v1.html(html, height=700)

# ---------------- STREAMLIT UI ---------------- #
# CHANGEMENT 1: Nom de la page (Utilisation de Axiom AI)
st.set_page_config(page_title="Axiom", layout="wide")
# CHANGEMENT 2: Titre principal (Utilisation de Axiom AI)
st.title("‚ú® Axiom ‚Ä¢ Data Quality & Audit")
st.markdown("Audit & nettoyage **intelligent** ")
st.divider() # AJOUT 1: S√©parateur visuel apr√®s le titre pour plus de clart√©

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    params = {
        "drop_dup":  st.checkbox("Supprimer doublons", True),
        "norm_cols": st.checkbox("Normaliser colonnes", True),
        "auto_type": st.checkbox("Conversion auto types", True),
        "text_clean": st.checkbox("Nettoyage Texte (strip, minuscule)", True),
        "iqr_coeff": st.slider("Coefficient IQR (Outliers)", 0.0, 3.0, 1.5, 0.1), # Changement de checkbox √† slider
        "drop_low_var": st.checkbox("Supprimer colonnes √† faible variance", False),
        "handle_na": st.checkbox("G√©rer NA", True),
        "na_thresh": st.slider("Taux min valeurs valides (%)", 50, 90, 70),
        "na_strat":  st.selectbox("Strat√©gie NA num", ["median", "mode"]),
        "na_fill":   st.text_input("Valeur remplacement NA texte", "_MISSING_"),
        "minimal":   st.checkbox("Mode ydata minimal (rapide)", True),
    }
    if st.button("üóëÔ∏è vider fichiers temp"):
        shutil.rmtree(TEMP_DIR, ignore_errors=True); TEMP_DIR.mkdir(exist_ok=True); st.success("Temp vid√©")
    st.info(f"Syst√®me: {platform.system()} | Dossier: {TEMP_DIR}")

# ---------------- CHARGEMENT ---------------- #
uploaded = st.file_uploader("üìÇ S√©lectionnez votre fichier",
                            type=["csv","xlsx","json","parquet","txt"], accept_multiple_files=False)
if not uploaded:
    st.info("Chargez un fichier pour commencer l'analyse de qualit√© des donn√©es.", icon="üí°") # AJOUT 2: Message d'attente pro
    st.stop()
if uploaded.size > MAX_SIZE:
    st.error("Fichier > 500 Mo refus√©"); st.stop()

@st.cache_data(show_spinner=False)
def load(uploaded):
    try:
        ext = Path(uploaded.name).suffix.lower()
        buffer = io.BytesIO(uploaded.getbuffer())

        # --- Gestion des .csv et .txt ---
        if ext in [".csv", ".txt"]:
            try:
                # 1Ô∏è Tentative de lecture tabulaire
                df = pd.read_csv(
                    buffer,
                    encoding="utf-8",
                    sep=None,              # d√©tection automatique du s√©parateur
                    engine="python",
                    quoting=csv.QUOTE_MINIMAL,
                    on_bad_lines="skip"
                )
                return df
            except Exception:
                # 2Ô∏èTentative JSON Lines (si le txt contient du JSON)
                buffer.seek(0)
                try:
                    df = pd.read_json(buffer, lines=True)
                    return df
                except Exception:
                    # 3Ô∏èLecture texte brut ‚Üí DataFrame √† une colonne
                    buffer.seek(0)
                    content = buffer.read().decode("utf-8", errors="ignore")
                    return pd.DataFrame({"texte": [content]})

        # --- Autres formats classiques ---
        elif ext == ".xlsx":
            return pd.read_excel(buffer)
        elif ext == ".json":
            return pd.read_json(buffer)
        elif ext == ".parquet":
            return pd.read_parquet(buffer)

    except Exception as e:
        log.exception("Erreur de chargement du fichier")
        st.error(str(e))
    return None


df_raw = load(uploaded)
if df_raw is None:
    st.stop()

df_opt, gain = memory_opt(df_raw)

# DEBUT AMELIORATION VISUELLE: Aper√ßu des m√©triques cl√©s
st.subheader(" Aper√ßu du Dataset Brut")
st.markdown("Les m√©triques ci-dessous sont calcul√©es sur le fichier brut avant nettoyage.")
st.divider()

col1, col2, col3, col4 = st.columns(4)
col1.metric("Total Lignes", f"{len(df_raw):,}")
col2.metric("Total Colonnes", len(df_raw.columns))
# Utilisation de Delta pour montrer l'impact des NA
total_cells = len(df_raw) * len(df_raw.columns)
na_count = df_raw.isna().sum().sum()
na_percentage = na_count * 100 / total_cells if total_cells > 0 else 0

col3.metric("NA", na_count, f"{na_percentage:.2f}% des cellules", delta_color="inverse")
col4.metric("Optimisation RAM", f"{gain:.1f}%", "R√©duction potentielle", delta_color="normal")
st.divider()
# FIN AMELIORATION VISUELLE

if st.button(" Lancer l‚Äôanalyse compl√®te", type="primary"):
    bar = st.progress(0)
    bar.progress(10)
    report_before = build_report(df_opt, "Avant", params["minimal"])
    bar.progress(40)
    df_clean, logs = clean_df(df_opt, params)
    bar.progress(70)
    report_after = build_report(df_clean, "Apr√®s", params["minimal"])
    bar.progress(100)
    st.session_state["before"] = df_opt
    st.session_state["after"]  = df_clean
    st.session_state["rep_bef"] = report_before
    st.session_state["rep_aft"] = report_after
    st.session_state["logs"]    = logs
    st.rerun()

if "after" not in st.session_state:
    st.stop()

bef, aft = st.session_state["before"], st.session_state["after"]
tab1, tab2, tab3, tab4 = st.tabs(["Rapport Avant nettoyage", "üßπ Nettoyage", "üìà Rapport Apr√®s nettoyage + Export", "ü§ñ Assistant IA"])

with tab1:
    st.subheader("Rapport avant nettoyage")
    if (p := st.session_state["rep_bef"]):
        st.download_button("üì• T√©l√©charger HTML", data=p.read_bytes(), file_name=p.name, mime="text/html")
        show_report(p)
    else:
        fallback_report(bef, "Avant")

with tab2:
    st.success(f"{len(st.session_state['logs'])} transformations")
    for l in st.session_state["logs"]:
        st.write("‚Ä¢", l)
    st.dataframe(aft.head(10))

with tab3:
    st.subheader("Rapport apr√®s nettoyage")
    if (p := st.session_state["rep_aft"]):
        st.download_button("üì• T√©l√©charger HTML", data=p.read_bytes(), file_name=p.name, mime="text/html")
        show_report(p)
    else:
        fallback_report(aft, "Apr√®s")
    fmt = st.selectbox("Exporter dataset nettoy√©", ["csv", "xlsx", "json", "parquet"])
    buf = io.BytesIO()
    match fmt:
        case "csv":      aft.to_csv(buf, index=False)
        case "xlsx":     aft.to_excel(buf, index=False)
        case "json":     buf.write(aft.to_json(orient="records", indent=2).encode())
        case "parquet":  aft.to_parquet(buf)
    buf.seek(0)
    st.download_button("üíæ T√©l√©charger dataset", data=buf, file_name=f"clean.{fmt}")

# ---------------- RECOS & CHAT INTELLIGENTS ---------------- #
# Remplacer TOUT le contenu de `with tab4:` par :

with tab4:
    st.header("ü§ñ Assistant IA ‚Äì Intelligence Contextuelle")
    
    # Initialisation
    if "chat" not in st.session_state:
        st.session_state.chat = []
    
    # Analyser le dataset une fois
    if "dataset_profile" not in st.session_state and aft is not None:
        with st.spinner("üîç Analyse intelligente du dataset en cours..."):
            st.session_state.dataset_profile = analyze_dataset_profile(aft)
    
    profile = st.session_state.get("dataset_profile", {})
    
    # Afficher l'analyse du dataset
    if profile:
        with st.expander("Profil d√©tect√© du Dataset", expanded=False):
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Type", profile["type"].title())
            with col2:
                st.metric("Score Qualit√©", f"{profile['quality_score']:.0f}/100")
            with col3:
                domains = ", ".join(profile["domain_hints"][:2]) or "G√©n√©ral"
                st.metric("Domaines", domains)
            
            if profile["characteristics"]:
                st.caption("**Caract√©ristiques:**")
                for char in profile["characteristics"][:3]:
                    st.write(f"‚Ä¢ {char}")
    
    # Section 1: Questions sugg√©r√©es intelligentes
    st.subheader("üí° Questions sugg√©r√©es")
    
    if profile and profile.get("suggested_questions"):
        # Organiser en 2 colonnes
        col1, col2 = st.columns(2)
        
        questions = profile["suggested_questions"]
        mid = len(questions) // 2
        
        with col1:
            for idx, question in enumerate(questions[:mid]):
                if st.button(f"{question[:50]}...", 
                           key=f"sugg_{idx}", 
                           use_container_width=True,
                           type="secondary"):
                    with st.spinner("Analyse en cours..."):
                        # Construire le prompt adaptatif
                        prompt = build_adaptive_prompt(aft, question, profile)
                        
                        # Appel LLM adaptatif
                        answer = ask_llama(
                            prompt=prompt,
                            max_tokens=400,
                            temperature=0.2,
                            profile=profile
                        )
                        
                        if answer:
                            st.session_state.chat.append(("user", question))
                            st.session_state.chat.append(("bot", answer))
        
        with col2:
            for idx, question in enumerate(questions[mid:], start=mid):
                if st.button(f"{question[:50]}...", 
                           key=f"sugg_{idx}", 
                           use_container_width=True,
                           type="secondary"):
                    with st.spinner("Analyse en cours..."):
                        prompt = build_adaptive_prompt(aft, question, profile)
                        answer = ask_llama(
                            prompt=prompt,
                            max_tokens=400,
                            temperature=0.2,
                            profile=profile
                        )
                        
                        if answer:
                            st.session_state.chat.append(("user", question))
                            st.session_state.chat.append(("bot", answer))
    else:
        # Questions par d√©faut si pas de profil
        default_questions = [
            "R√©sume la qualit√© de ce dataset",
            "Quels probl√®mes potentiels vois-tu?",
            "Propose des am√©liorations de nettoyage"
        ]
        
        cols = st.columns(3)
        for idx, question in enumerate(default_questions):
            with cols[idx]:
                if st.button(question, use_container_width=True, type="secondary"):
                    with st.spinner("Analyse..."):
                        answer = ask_llama(question, 350, 0.2)
                        if answer:
                            st.session_state.chat.append(("user", question))
                            st.session_state.chat.append(("bot", answer))
    
    st.divider()
    
    # Section 2: Chat intelligent principal
    st.subheader("üí¨ Conversation avec l'IA")
    
    # Input utilisateur
    user_input = st.text_area(
        "Posez votre question sp√©cifique:",
        placeholder="Ex: Comment puis-je am√©liorer la qualit√© de ces donn√©es pour une analyse ML?",
        height=100,
        key="user_input"
    )
    
    # Boutons d'action
    col_send, col_clear, col_regen = st.columns([2, 1, 1])
    
    with col_send:
        send_disabled = not user_input.strip() or not st.secrets.get("OPENROUTER_KEY")
        if st.button("Analyser avec IA", 
                    type="primary", 
                    use_container_width=True,
                    disabled=send_disabled):
            
            with st.spinner("üîç Analyse contextuelle en cours..."):
                # Construire le prompt adaptatif si profil disponible
                if profile:
                    prompt = build_adaptive_prompt(aft, user_input, profile)
                    max_tokens = 450 if len(user_input) > 100 else 350
                else:
                    prompt = user_input
                    max_tokens = 350
                
                # Appel LLM
                response = ask_llama(
                    prompt=prompt,
                    max_tokens=max_tokens,
                    temperature=0.2,
                    profile=profile
                )
                
                # Ajouter √† l'historique
                st.session_state.chat.append(("user", user_input))
                st.session_state.chat.append(("bot", response or "D√©sol√©, je n'ai pas pu g√©n√©rer de r√©ponse."))
                
                st.rerun()
    
    with col_clear:
        if st.button("üóëÔ∏è Effacer chat", use_container_width=True):
            st.session_state.chat = []
            st.rerun()
    
    with col_regen:
        if st.button("üîÑ Re-analyser dataset", use_container_width=True):
            if aft is not None:
                with st.spinner("Nouvelle analyse du dataset..."):
                    st.session_state.dataset_profile = analyze_dataset_profile(aft)
                st.success("Dataset r√©-analys√©!")
                st.rerun()
    
    # Section 3: Affichage de l'historique
    st.divider()
    
    if st.session_state.chat:
        st.subheader("üìú Historique")
        
        for i in range(0, len(st.session_state.chat), 2):
            if i + 1 < len(st.session_state.chat):
                user_msg = st.session_state.chat[i][1]
                bot_msg = st.session_state.chat[i + 1][1]
                
                # Message utilisateur
                with st.chat_message("user"):
                    st.write(user_msg)
                
                # Message IA avec contexte
                with st.chat_message("assistant"):
                    # Ajouter un badge contextuel si profil disponible
                    if profile:
                        badge = f"**ü§ñ Axiom AI ‚Ä¢ {profile['type'].title()}**"
                        st.markdown(badge)
                        st.markdown("---")
                    
                    st.write(bot_msg)
                    
                    # Boutons d'action pour chaque r√©ponse
                    col_copy, col_expand = st.columns([1, 3])
                    with col_copy:
                        if st.button("üìã", key=f"copy_{i//2}", help="Copier"):
                            st.code(bot_msg, language=None)
                    
        # Bouton pour tout effacer en bas
        if st.button("üóëÔ∏è Effacer toute la conversation", type="secondary"):
            st.session_state.chat = []
            st.rerun()
    else:
        # √âtat initial - conseils contextuels
        st.info("**Comment utiliser l'assistant IA intelligent:**")
        
        advice_cols = st.columns(2)
        
        with advice_cols[0]:
            st.markdown("""
            **Pour de meilleurs r√©sultats:**
            1. Posez des questions sp√©cifiques
            2. Mentionnez vos objectifs
            3. Demandez des recommandations concr√®tes
            4. Utilisez les questions sugg√©r√©es
            """)
        
        with advice_cols[1]:
            if profile:
                st.markdown(f"""
                **Contexte d√©tect√©:**
                - Type: **{profile['type'].title()}**
                - Domaine: **{', '.join(profile['domain_hints'][:2]) or 'G√©n√©ral'}**
                - Qualit√©: **{profile['quality_score']:.0f}/100**
                
                L'IA adaptera ses r√©ponses √† ce contexte.
                """)
            else:
                st.markdown("""
                **Analyse en cours...**
                L'IA analysera automatiquement
                votre dataset pour des r√©ponses
                plus pertinentes.
                """)
